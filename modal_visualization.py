# -*- coding: utf-8 -*-
"""modal visualization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1InQVXdPAbMxNKwkCMJZZ0VQB6d0PLQiK
"""

from google.colab import drive
drive.mount('/content/gdrive')

import json

! pip install pandas
import pandas as pd
import numpy as np

! pip install dfply
from dfply import *

"""### create initial list of scenarios"""

scenario_list2 = [
    {   "scenNo": "scenario1",
        "scen_content": "Heinzs wife has recently fallen ill and needs an expensive medication that is not covered by her medical insurance. They do not have the money needed to purchase the expensive prescription medication, but they know that it is vital for her to have it if she is going to recover.",
        "studyNo": "1"
    },

    {
        "scenNo": "scenario2",
        "scen_content": "Josh is on the way to the airport to catch a flight for a hunting safari in Africa. He leaves with plenty of time to make it there, but his car breaks down on the highway. Now Josh is sitting in his car near a busy intersection, and knows he needs to get to airport soon if he is going to catch his flight.",
        "studyNo": "1"
    },

    {
        "scenNo": "scenario3",
        "scen_content": "Brian is the evening manager at a bakery. Near the end of the day, he realizes that $50.75 is missing from the register and that he is responsible for accounting for the money at the end of the day. Brian knows he has to make sure the register is balanced or he might lose his job.",
        "studyNo": "1"
    }, 
   
    {
        "scenNo": "scenario4",
        "scen_content": "Liz decides to go to the gym on her lunch break because she is going to have to work late tonight and won't have time during the evening. When she gets to the gym, she realizes that her membership has expired since she last went.",
        "studyNo": "1"
    },

    {
        "scenNo": "scenario5",
        "scen_content": "Mary is about to go to her final class of the day when she remembers that there is a homework assignment that is due. Mary's mom accidentally took her homework assignment out of her backpack when she was making room for her lunch. Now Mary has nothing to turn in for credit.",
        "studyNo": "1"
    },
  
    {
        "scenNo": "scenario6",
        "scen_content": "Brad and some friends are hiking through the mountains in the Canadian wilderness. A couple of days into their hike, Brad realizes that they are lost. He knows that a rescue crew could arrive before long, but it is extremely cold and they don't have much food or water left.",
        "studyNo": "1"
    },

    {
        "scenNo": "scenario7",
        "scen_content": "As you enter a museum, the security guard informs you that you must leave your backpack at the coat check. While you are in the museum...",
        "studyNo": "2"
    },

    {
        "scenNo": "scenario8",
        "scen_content": "You are eating dinner at a buffet-style restaurant, in which you pay upfront for your meal and fill your plate from serving platters. While you are in the restaurant...",
        "studyNo": "2"
    },

    {
        "scenNo": "scenario9",
        "scen_content": "You are at a public library, walking up and down the aisles in search of a book to read. While you are in the library...",
        "studyNo": "2"
    },

    {
        "scenNo": "scenario10",
        "scen_content": "You are on a flight. The flight attendant is walking through the main cabin with refreshments. While you are on your flight...",
        "studyNo": "2"
    },

    {
        "scenNo": "scenario11",
        "scen_content": "You are on the planning committee for an event your organization is organizing, and the next meeting is in fifteen minutes. While you are on your way to the meeting...",
        "studyNo": "2"
    },

    {
        "scenNo": "scenario12",
        "scen_content": "You are in a 100-person lecture hall class. The professor is currently going over new material. While you are in class...",
        "studyNo": "2"
    },

    {
        "scenNo": "scenario13",
        "scen_content": "You are working late at your office to finish a project. All of your co-workers have gone home for the night. While you are in the empty office...",
        "studyNo": "2"
    },

    {
        "scenNo": "scenario14",
        "scen_content": "You enter the elevator in a tall office building, joining a handful of other passengers. While you are riding the elevator...",
        "studyNo": "2"
    }

]

with open('/content/gdrive/MyDrive/modal_visualization/scenario_list2.json', 'w') as f:
    json.dump(scenario_list2, f)

"""### define functions"""

## SELECT RELEVANT COLUMNS
#for mTurk data
def select_cols(dataframe):
    dataframe['responses'] = dataframe['responses'].replace(['f'], 1) # changes value of 'f' under column 'responses' to 1
    dataframe['responses'] = dataframe['responses'].replace(['j'], 0)
    dataframe['responses'] = dataframe['responses'].replace(['timeout'], 99)
    dataframe['condition3'] = dataframe['condition3'].replace(['fast'], 'speeded')
    dataframe['condition3'] = dataframe['condition3'].replace(['slow'], 'reflective')
    dataframe['responses'] = dataframe['responses'].astype(float) # converts responses to float
    
    
    result = dataframe >> select(X.condition1, X.condition2, X.condition3, X.target, X.RTs, X.responses, X.trialNo,
                             X.turkID) \
             >> filter_by(X.condition1 != 'na') \
             >> filter_by(X.responses != 99) \
             #>> mutate(trialNo=X.trialNo)
    result['trialNo'] = result['trialNo'].astype(int)
    return result



## EXCLUDE RESPONSE, COMPUTE MEAN RT AND RESPONSE
def filterfunc(dataframe):
    dataframe['trialNo'] = dataframe['trialNo'].astype(int)
    speeded = dataframe >> filter_by(X.condition3 != 'na') \
              >> filter_by(X.RTs <= 6000) \
              >> filter_by(X.condition3 == 'speeded') \
              >> select(X.trialNo, X.responses, X.turkID, X.condition3, X.RTs) \
              >> group_by(X.turkID) \
              >> summarize(mean_RT_s=mean(X.RTs)) \
              >> filter_by(X.mean_RT_s < 800)

    reflective = dataframe >> filter_by(X.condition3 != 'na') \
                 >> filter_by(X.RTs <= 6000) \
                 >> filter_by(X.condition3 == 'reflective') \
                 >> select(X.trialNo, X.responses, X.turkID, X.condition3, X.RTs) \
                 >> group_by(X.turkID) \
                 >> summarize(mean_RT_r=mean(X.RTs)) \
                 >> filter_by(X.mean_RT_r < 1000)

    final_speeded = dataframe[~dataframe.turkID.isin(speeded.turkID)] \
                    >> filter_by(X.condition3 == 'speeded') \
                    >> filter_by(X.RTs > 500) \
                    >> select(X.turkID, X.trialNo, X.condition3, X.responses, X.RTs) \
                    >> group_by(X.trialNo) >> summarize(mean_response_sp=mean(X.responses), mean_RT_s=mean(X.RTs))

    final_reflective = dataframe[~dataframe.turkID.isin(reflective.turkID)] \
                       >> filter_by(X.condition3 == 'reflective') \
                       >> filter_by(X.RTs > 1500) \
                       >> select(X.trialNo, X.responses, X.turkID, X.condition3, X.RTs) \
                       >> group_by(X.trialNo) >> summarize(mean_response_rf=mean(X.responses), mean_RT_r=mean(X.RTs))
    
    #target = should_data.sort_values('trialNo').groupby('trialNo').nth(0).iloc[:,[0,1,3]]
    #not the most elegant method, but unaffected by typos/inconsistencies in trial files

    final_merged = pd.merge(final_speeded, final_reflective,on='trialNo', how='left') >> arrange(X.trialNo, ascending=True)
    return final_merged



##
def event_rating_transformation(dataframe):
    result = dataframe >> select(X.condition1, X.condition2, X.trialNo, X.target, X.responses, X.RTs) \
             >> mutate(judgment=dataframe.target.apply(
        lambda x: 1 if 'moral' in x else 2 if 'rational' in x else 3 if 'likely' in x else x)) \
             >> group_by(X.trialNo, X.condition1, X.condition2, X.judgment) \
             >> summarize(meanresponse=mean(X.responses)) \
             >> select(X.condition1, X.condition2, X.trialNo, X.judgment, X.meanresponse) \
             >> spread(X.judgment, X.meanresponse)
    result.columns = ['condition1', 'condition2', 'trialNo', 'meanRating_moral', 'meanRating_rational', 'meanRating_likely']
    result['trialNo'] = result['trialNo'].astype(int)
    return result
  

###
def joinfunc(main, data):
    result = pd.merge(main, data, on='trialNo', how='outer')
    return result

def joinfunc_multi(main, list):
    result = main
    for x in list:
      result = joinfunc(result, x)
    return result

###
def get_event_list(dataframe):
    dataframe['trialNo'] = dataframe['trialNo'].astype(int)
    result = dataframe.sort_values('trialNo').groupby('trialNo').nth(0)['target']
    return result
  
#should_data.sort_values('trialNo').groupby('trialNo').nth(0)['target']

"""#### for prolific data"""

#for prolific
def select_cols_p(dataframe):
    dataframe['response'] = dataframe['response'].replace(['f'], 1) # changes value of 'f' under column 'responses' to 1
    dataframe['response'] = dataframe['response'].replace(['j'], 0)
    dataframe['response'] = dataframe['response'].replace(['timeout'], 99)
    #dataframe['condition3'] = dataframe['condition3'].replace(['fast'], 'speeded')
    #dataframe['condition3'] = dataframe['condition3'].replace(['slow'], 'reflective')
    
    result = dataframe >> select(X.condition1, X.condition2, X.condition3, X.target, X.RT, X.response, X.trialNo,
                             X.id) \
             >> filter_by(X.condition1 != 'break') \
             >> filter_by(X.response != 99) \
             >> mutate(trialNo=X.trialNo)
    result['trialNo'] = result['trialNo'].astype(int)
    #dataframe['response'] = dataframe['response'].astype(float) # converts responses to float
    #
    return result


#filter function for prolific data
def filterfunc_p(dataframe):
    dataframe['trialNo'] = dataframe['trialNo'].astype(int)
    dataframe['response'] = dataframe['response'].astype(float)
    #dataframe['RT'] = dataframe['RT'].astype(float)

    speeded = dataframe >> filter_by(X.condition3 != 'na') \
              >> filter_by(X.RT <= 6000) \
              >> filter_by(X.condition3 == 'speeded') \
              >> select(X.trialNo, X.response, X.id, X.condition3, X.RT) \
              >> group_by(X.id) \
              >> summarize(mean_RT_s=mean(X.RT)) \
              >> filter_by(X.mean_RT_s < 800)

    reflective = dataframe >> filter_by(X.condition3 != 'na') \
                 >> filter_by(X.RT <= 6000) \
                 >> filter_by(X.condition3 == 'reflective') \
                 >> select(X.trialNo, X.response, X.id, X.condition3, X.RT) \
                 >> group_by(X.id) \
                 >> summarize(mean_RT_r=mean(X.RT)) \
                 >> filter_by(X.mean_RT_r < 1000)

    final_speeded = dataframe[~dataframe.id.isin(speeded.id)] \
                    >> filter_by(X.condition3 == 'speeded') \
                    >> filter_by(X.RT > 500) \
                    >> select(X.id, X.trialNo, X.condition3, X.response, X.RT) \
                    >> group_by(X.trialNo) >> summarize(mean_response_sp=mean(X.response), mean_RT_s=mean(X.RT))

    final_reflective = dataframe[~dataframe.id.isin(reflective.id)] \
                       >> filter_by(X.condition3 == 'reflective') \
                       >> filter_by(X.RT > 1500) \
                       >> select(X.trialNo, X.response, X.id, X.condition3, X.RT) \
                       >> group_by(X.trialNo) >> summarize(mean_response_rf=mean(X.response), mean_RT_r=mean(X.RT))
    
    
    final_merged = pd.merge(final_speeded, final_reflective,on='trialNo', how='left') >> arrange(X.trialNo, ascending=True)
    return final_merged

"""###dataset#1 (Darley)

#### transform dataframes
"""

#
possibility_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/study1possibilityData.csv")
event_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/study1eventData.csv")
could_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/study2couldData.csv")
may_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/study2mayData.csv")
might_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/study2mightData.csv")
ought_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/study2oughtData.csv")
should_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/study2shouldData.csv")

## event-item ratings
event_rating_df = event_rating_transformation(event_data)

#event_rating_df

## response & meanRTs
# Possibility
poss_df = select_cols(possibility_data)
poss_filter = filterfunc(poss_df) >> rename(poss_resp_s=X.mean_response_sp, poss_meanRT_s=X.mean_RT_s, poss_resp_rf=X.mean_response_rf, poss_meanRT_rf=X.mean_RT_r)
#main = joinfunc(main, poss_filter)

# Could
could_df = select_cols(could_data)
could_filter = filterfunc(could_df) >> rename(could_resp_s=X.mean_response_sp, could_meanRT_s=X.mean_RT_s, could_resp_rf=X.mean_response_rf, could_meanRT_rf=X.mean_RT_r)
#main = joinfunc(main, could_filter)

# MAY
may_df = select_cols(may_data)
may_filter = filterfunc(may_df) >> rename(may_resp_s=X.mean_response_sp, may_meanRT_s=X.mean_RT_s, may_resp_rf=X.mean_response_rf, may_meanRT_rf=X.mean_RT_r)
#main = joinfunc(main, may_filter)

# MIGHT
might_df = select_cols(might_data)
might_filter = filterfunc(might_df) >> rename(might_resp_s=X.mean_response_sp, might_meanRT_s=X.mean_RT_s, might_resp_rf=X.mean_response_rf, might_meanRT_rf=X.mean_RT_r)
#main = joinfunc(main, might_filter)

# OUGHT
ought_df = select_cols(ought_data)
ought_filter = filterfunc(ought_df) >> rename(ought_resp_s=X.mean_response_sp, ought_meanRT_s=X.mean_RT_s, ought_resp_rf=X.mean_response_rf, ought_meanRT_rf=X.mean_RT_r)
#main = joinfunc(main, ought_filter)

# SHOULD
should_df = select_cols(should_data)
should_filter = filterfunc(should_df) >> rename(should_resp_s=X.mean_response_sp, should_meanRT_s=X.mean_RT_s, should_resp_rf=X.mean_response_rf, should_meanRT_rf=X.mean_RT_r)
#main = joinfunc(main, should_filter)

## list of events
event_list = poss_df.sort_values('trialNo').groupby('trialNo').nth(0)['target']
event_list

"""#### combine dataframes"""

##
#event list & rating
main = pd.merge(event_list, event_rating_df,on='trialNo', how='left') >> arrange(X.trialNo, ascending=True)
#  + response and meanRT
main = joinfunc_multi(main,[poss_filter, could_filter, may_filter, might_filter, ought_filter, should_filter])

main.to_csv('/content/drive/MyDrive/modal_visualization/datasets/studyNo1(Darley)/main_response_1.csv', index=False)

"""### dataset#2(EJ)

(the data i'm using here already have the trial numbers replaced)

#### transform dataframes
"""

ej_could_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo2(EJ)/upd_ej_could_data.csv")
ej_may_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo2(EJ)/upd_ej_may_data.csv")
ej_might_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo2(EJ)/upd_ej_might_data.csv")
ej_ought_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo2(EJ)/upd_ej_ought_data.csv")
ej_should_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo2(EJ)/upd_ej_should_data.csv")
ej_poss_data = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo2(EJ)/upd_ej_possibility_data.csv")

#Could
ej_could_df = select_cols(ej_could_data)
ej_could_filter = filterfunc(ej_could_df) >> rename(could_resp_s=X.mean_response_sp, could_meanRT_s=X.mean_RT_s, could_resp_rf=X.mean_response_rf, could_meanRT_rf=X.mean_RT_r)

# MAY
ej_may_df = select_cols(ej_may_data)
ej_may_filter = filterfunc(ej_may_df) >> rename(may_resp_s=X.mean_response_sp, may_meanRT_s=X.mean_RT_s, may_resp_rf=X.mean_response_rf, may_meanRT_rf=X.mean_RT_r)

# MIGHT
ej_might_df = select_cols(ej_might_data)
ej_might_filter = filterfunc(ej_might_df) >> rename(might_resp_s=X.mean_response_sp, might_meanRT_s=X.mean_RT_s, might_resp_rf=X.mean_response_rf, might_meanRT_rf=X.mean_RT_r)

# OUGHT
ej_ought_df = select_cols(ej_ought_data)
ej_ought_filter = filterfunc(ej_ought_df) >> rename(ought_resp_s=X.mean_response_sp, ought_meanRT_s=X.mean_RT_s, ought_resp_rf=X.mean_response_rf, ought_meanRT_rf=X.mean_RT_r)

# SHOULD
ej_should_df = select_cols(ej_should_data)
ej_should_filter = filterfunc(ej_should_df) >> rename(should_resp_s=X.mean_response_sp, should_meanRT_s=X.mean_RT_s, should_resp_rf=X.mean_response_rf, should_meanRT_rf=X.mean_RT_r)

# Possibility
ej_poss_df = select_cols(ej_poss_data)
ej_poss_filter = filterfunc(ej_poss_df) >> rename(poss_resp_s=X.mean_response_sp, poss_meanRT_s=X.mean_RT_s, poss_resp_rf=X.mean_response_rf, poss_meanRT_rf=X.mean_RT_r)
#

## event list
ej_event_list = ej_could_df.sort_values('trialNo').groupby('trialNo').nth(0)[['target','condition1','condition2']]

#correct scenNo
ej_event_list = ej_event_list.replace({'condition2' : {'scenario1':'scenario7', 'scenario2':'scenario8', 'scenario3':'scenario9',
                                                       'scenario4':'scenario10', 'scenario5':'scenario11', 'scenario6':'scenario12',
                                                       'scenario7':'scenario13', 'scenario8':'scenario14'}})
#ej_event_list

#ej_main = pd.merge(ej_event_list, ej_could_filter,on='trialNo', how='outer') >> arrange(X.trialNo, ascending=True)

ej_main = joinfunc_multi(ej_event_list,[ej_poss_filter, ej_could_filter, ej_may_filter, ej_might_filter, ej_ought_filter, ej_should_filter])

##to be edited later
ej_main = ej_main.replace({'condition2' : {'scenario1':'scenario7', 'scenario2':'scenario8', 'scenario3':'scenario9',
                                                       'scenario4':'scenario10', 'scenario5':'scenario11', 'scenario6':'scenario12',
                                                       'scenario7':'scenario13', 'scenario8':'scenario14'}})

#ej_main

ej_main.to_csv('/content/drive/MyDrive/modal_visualization/datasets/studyNo2(EJ)/main_response_2.csv', index=False)

"""### datatset#3(MoralModals)

####tranform dataframe
"""

could_data_3 = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo3(MoralModals)/MoralModals_full_could.csv")
may_data_3 = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo3(MoralModals)/MoralModals_full_may.csv")
might_data_3 = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo3(MoralModals)/MoralModals_full_might.csv")
ought_data_3 = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo3(MoralModals)/MoralModals_full_ought.csv")

# Could
could_df_3 = select_cols_p(could_data_3)
could_filter_3 = filterfunc_p(could_df_3) >> rename(could_resp_s=X.mean_response_sp, could_meanRT_s=X.mean_RT_s, could_resp_rf=X.mean_response_rf, could_meanRT_rf=X.mean_RT_r)

# MAY
may_df_3 = select_cols_p(may_data_3)
may_filter_3 = filterfunc_p(may_df_3) >> rename(may_resp_s=X.mean_response_sp, may_meanRT_s=X.mean_RT_s, may_resp_rf=X.mean_response_rf, may_meanRT_rf=X.mean_RT_r)

# MIGHT
might_df_3 = select_cols_p(might_data_3)
might_filter_3 = filterfunc_p(might_df_3) >> rename(might_resp_s=X.mean_response_sp, might_meanRT_s=X.mean_RT_s, might_resp_rf=X.mean_response_rf, might_meanRT_rf=X.mean_RT_r)

# OUGHT
ought_df_3 = select_cols_p(ought_data_3)
ought_filter_3 = filterfunc_p(ought_df_3) >> rename(ought_resp_s=X.mean_response_sp, ought_meanRT_s=X.mean_RT_s, ought_resp_rf=X.mean_response_rf, ought_meanRT_rf=X.mean_RT_r)

#event list
event_list_3 = could_df_3.sort_values('trialNo').groupby('trialNo').nth(0)[['condition2','condition1','target']]
event_list_3

#combine & change trialNo and scenNo
main_3 = joinfunc_multi(event_list_3,[could_filter_3, may_filter_3, might_filter_3, ought_filter_3])

#change trialNo (+252, 21-->273)
main_3['trialNo'] = main_3['trialNo'] + 252

#change scenNo
main_3 = main_3.replace({'condition2' : {'scenario1':'scenario15', 'scenario2':'scenario16', 'scenario3':'scenario17',
                                                       'scenario4':'scenario18', 'scenario5':'scenario19', 'scenario6':'scenario20',
                                                       'scenario7':'scenario21', 'scenario8':'scenario22','scenario9':'scenario23', 
                                         'scenario10':'scenario24', 'scenario11':'scenario25','scenario12':'scenario26'}})


main_3.to_csv('/content/drive/MyDrive/modal_visualization/datasets/studyNo3(MoralModals)/main_response.csv', index=False)

"""#combine datasets

###combine response dfs
"""

#master_df2 = pd.merge(master_df, ej_main, on="condition2", how="left")
#master_df2

main_combined = pd.concat([main, ej_main, main_3])


main_combined.to_csv('/content/drive/MyDrive/modal_visualization/main_combined(1.13).csv', index=False)

"""###add to scenario list"""

#
scen_list = pd.read_json("/content/drive/MyDrive/modal_visualization/scenario_list2.json")
scen_list = scen_list[['studyNo', 'scenNo', 'scen_content']]
scen_list=scen_list.rename(columns = {'scenNo':'condition2'})
scen_list

#add scens from study3
scen_list_3 = pd.read_csv("/content/drive/MyDrive/modal_visualization/datasets/studyNo3(MoralModals)/scen_list_3.csv")

scen_list = pd.concat([scen_list,scen_list_3])
scen_list #note scen3 &scen16

main_final = pd.merge(scen_list, main_combined, on="condition2", how="right")
main_final

main_final.to_csv('/content/drive/MyDrive/modal_visualization/main_final(1.13).csv', index=False)

"""##notes:
- add moral modals date
- find EJ's event rating
- clean code, fix path problems etc.

### scrap paper
"""

#target = should_data.sort_values('trialNo').groupby('trialNo').nth(0).iloc[:,[0,1,3]]


#target = target.groupby('trialNo').nth(0).iloc[:,[0,1,3]]
#target